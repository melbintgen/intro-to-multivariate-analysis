---
title: "Introduction to multivariate analysis with mixOmics"
author: "Kim-Anh LÃª Cao"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  html_document:
    df_print: paged
    toc: yes
    toc_float: yes
    toc_depth: '3'
  html_notebook:
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: 3
editor_options: 
  markdown: 
    wrap: 72
  chunk_output_type: console
bibliography: ["bibliography.bib"]
biblio-style: apalike
link-citations: true
---

```{=html}
<!--
Show / hide answers to exercises.
Code adapted from: https://chrisbeeley.net/?p=1104
-->
```
```{=html}
<script>
function myFunction(id) {
    var x = document.getElementById(id);
    if (x.style.display === "none") {
        x.style.display = "block";
    } else {
        x.style.display = "none";
    }
}
</script>
```
```{=html}
<style>
div .info {
  margin: auto;
  background-color: #EAF0FB;
  width: 95%;
  padding: 10px;
}
</style>
```
```{r setup, include=FALSE}
# Smaller images for pdf
# knitr::opts_chunk$set(out.width="50%")
options(width=80)
```


```{r 01-options, include=FALSE}
library(knitr)
# global options
knitr::opts_chunk$set(dpi = 100, echo=TRUE, warning=FALSE, message=FALSE, eval = TRUE,
                      fig.show=TRUE, fig.width= 9,fig.height= 7.5,fig.align='center', out.width = '70%', message = FALSE)

colorize <- function(color, x) {
  if (knitr::is_html_output()) {
    htmlcolor = "black"
    if(color == "blue"){
      htmlcolor = "#388ECC"
    }
    if(color == "orange"){
      htmlcolor = "#F68B33"
    }
    if(color == "grey"){
      htmlcolor = "#585858"
    }
    if(color == "green"){
      htmlcolor = "#009E73"
    }
    if(color == "pink"){
      htmlcolor = "#CC79A7"
    }
    if(color == "yellow"){
      htmlcolor = "#999900"
    }
    if(color == "darkred"){
      htmlcolor = "#CC0000"
    }
    sprintf("<span style='color: %s;'>%s</span>", htmlcolor, x)
  } else {
    sprintf("\\textcolor{%s}{%s}", color, x)
    }
}
```
# Let's get started {#01}

## Installation {#01:install}

First, download the latest \texttt{mixOmics} version from Bioconductor [@Roh17]:

```{r 01-install-bioc, eval = FALSE}
if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
 BiocManager::install("mixOmics")
```


The `mixOmics` package should directly import the following packages:
`igraph, rgl, ellipse, corpcor, RColorBrewer, plyr, parallel, dplyr, tidyr, reshape2, methods, matrixStats, rARPACK, gridExtra`.

**For Apple mac users:** if you are unable to install the imported package `rgl`, you will need to install the [XQuartz software](https://www.xquartz.org) first.

## Load the package {#01:load-data}

```{r 01-load, message=FALSE}
library(mixOmics)
```

Check that there is no error when loading the package, especially for the `rgl` library (see above).

## Upload data
The examples in this workshop use data that are already part of the package. To upload your own data, check first that your working directory is set, then read your data from a  `.txt` or `.csv` format, either by using **File > Import Dataset** in RStudio or via one of these command lines:

```{r 01-read-data, eval = FALSE}
# from csv file
data <- read.csv("your_data.csv", row.names = 1, header = TRUE)

# from txt file
data <- read.table("your_data.txt", header = TRUE)
```

For more details about the arguments used to modify those functions, type `?read.csv` or `?read.table` in the R console.

## Quick start in `mixOmics` {#01:quick-start}

Each analysis should follow this workflow:

1. Run the method
2. Graphical representation of the samples
3. Graphical representation of the variables

Then use your critical thinking and additional functions and visual tools to make sense of your data! 

For instance, for Principal Components Analysis, we first load the data:

```{r 01-load-nutrimouse}
data(nutrimouse)       #load data
X <- nutrimouse$gene    #store data in object called X
```


Then use the following steps:

```{r 01-pca-nutrimouse, fig.show='hide'}
MyResult.pca <- pca(X)  # 1 Run the method PCA on X
plotIndiv(MyResult.pca) # 2 Plot the samples from a PCA result
plotVar(MyResult.pca)   # 3 Plot the variables from a PCA result
```


This is only a first quick-start. The package proposes several methods to perform variable selection and integration.


Following our example here, **sparse PCA** can be applied to select the top 5 variables contributing to each of the two components in PCA. The user specifies the number of variables to selected on each component, for example, here 5 variables are selected on each of the first two components (`keepX=c(5,5)`): 

```{r 01-spca-nutrimouse, fig.show='hide'}
MyResult.spca <- spca(X, keepX=c(5,5)) # 1 Run the method
plotIndiv(MyResult.spca)               # 2 Plot the samples
plotVar(MyResult.spca)                 # 3 Plot the variables
```

You can see know that we have considerably reduced the number of genes in the `plotVar` correlation circle plot.

# 1. PCA on the SRBCT case study {#01}

The Small Round Blue Cell Tumours (SRBCT) data set from [@Kha01] includes the expression levels of 2,308 genes measured on 63 samples. The samples are divided into four classes: 8 Burkitt Lymphoma (BL), 23 Ewing Sarcoma (EWS), 12 neuroblastoma (NB), and 20 rhabdomyosarcoma (RMS). The data are directly available in a processed and normalised format from the `mixOmics` package and contains the following:

- `$gene`: A data frame with 63 rows and 2,308 columns. These are the expression levels of 2,308 genes in 63 subjects,

- `$class`: A vector containing the class of tumour for each individual (4 classes in total),

- `$gene.name`: A data frame with 2,308 rows and 2 columns containing further information on the genes.

More details can be found in `?srbct`. 


## Load the data

We first load the data from the package and store the gene expression data in a  $\boldsymbol X$ object. 

```{r results = 'hide', message=FALSE}
library(mixOmics)
data(srbct)
X <- srbct$gene
dim(X)  # check dimension
```


## Exploration with PCA {#01:plsda-pca}

PCA is a useful tool to explore the gene expression data and to assess for sample similarities between tumour types sotred in `srbct$class`. Remember that PCA is an unsupervised approach, but we can colour the samples by their tumour subtype to assist in interpreting the PCA (Figure \@ref(fig:01-plsda-pca)). Here we center (default argument) and scale the data:

```{r 01-plsda-pca, fig.cap='(ref:01-plsda-pca)', fig.show='hide', results = 'hide'}
pca.srbct <- pca(X, ncomp = 10, scale = TRUE)

pca.srbct

plot(pca.srbct)

# simple version
plotIndiv(pca.srbct, 
          pch = 1,    # pch is to show symbols
          title = 'SRBCT, PCA comp 1 - 2')

# advanced version
plotIndiv(pca.srbct, 
          group = srbct$class, # asking to color according to class of tumour
          ind.names = FALSE,   # not showing the sample names
          legend = TRUE, 
          title = 'SRBCT, PCA comp 1 - 2')
```

## Exercise 1: Interpretation

Run the code above, line by line.

1. How many principal components would you retain, and why.

2. How is a sample plot obtained in PCA? What does it represent?

3. Interpret the sample plot outputs (the simple version first, then the advanced version). What is the major source of variation in the data?

<button onclick="myFunction(&#39;q1&#39;)">

Show solutions

</button>

::: {#q1 style="display:none"}

#### Answers

1. The first two components explain `r round(pca.srbct$cum.var[2]*100, 2)`% of the total variance. Based on the elbow method, we would choose 2 components.

2. A sample plot is obtained by plotting the components as a way to reduce the dimension of the data. It means that  samples are projected into the space spanned by the principal components 1 and 2. 

3. The tumour types are not clustered, meaning that the major source of variation cannot be explained by tumour types. Instead, samples seem to cluster according to an unknown source of variation. We observe almost no separation between the different tumour types in the PCA sample plot, with perhaps the exception of the `r colorize("grey", "NB")` samples that tend to cluster with other samples. This preliminary exploration teaches us two important findings:

Conclusions:

- The major source of variation is not attributable to tumour type, but an unknown source (we tend to observe clusters of samples but those are not explained by tumour type). 

- We need a more 'directed' (supervised) analysis to separate the tumour types, and we should expect that the amount of variance explained by the dimensions in PLS-DA analysis will be small.
:::

<!-- end solutions -->


# 2. PLS-DA on the SRBCT case study {#02}


## Set the outcome variable 

We have already loaded the SRBCT gene expression data and stored in $\boldsymbol X$.
We need to store the factor indicating the sample class membership in $\boldsymbol Y$


```{r results = 'hold', message=FALSE, results='hide'}
Y <- srbct$class 
length(Y)
```


## First pass: PLS-DA

We  run a PLS-DA model that includes three components:
```{r 01-plsda, results = 'hide', fig.show='hide'}
plsda.srbct <- plsda(X,Y, ncomp = 3)

plotIndiv(plsda.srbct, ind.names = FALSE, legend=TRUE,
          comp=c(1,2), 
          title = 'PLS-DA on SRBCT comp 1-2')

plotLoadings(plsda.srbct, 
             contrib = 'max',  # max = which class has maximum mean (median) expression (vs. min)
             method = 'mean',  # choose either mean or median
             comp = 1,
             ndisplay = 50)

plotVar(plsda.srbct, cutoff = 0.7)  # variable plot (correlation circle plot)

biplot(plsda.srbct, cutoff = 0.7)   # we set a correlation cutoff to only show the most contributing variables   

boxplot(X[, 'g1932']~ Y)
```


## Exercise 2: Interpretation

Run the code above, line by line.

1. Interpret the sample plot. What do you notice regarding the amount of explained variance per component, compared to PCA. Is this expected? Also inspect the sample plot for components 1 vs. 3.

2. Loadings plot: what does each bar represent? Change the parameters `r contrib = 'max'` to `r contrib = 'min'`. Change the parameter `r comp = 1` to  `r comp = 2`. What do you observe? Now, interpret the loading plot in combination with the sample plot. Does the loading plot make sense in light of this additional information?

3. Interpret the variable plot (correlation circle plot, refer to slides).

4. Interpret the biplot.

5. As a follow-up to the biplot interpretation, choose one gene and plot a boxplot with respect to the tumour subtype group (as shown). What is your interpretation?

<button onclick="myFunction(&#39;q2&#39;)">

Show solutions

</button>

::: {#q2 style="display:none"}

#### Answers

1.1 Amount of explained variance: while PCA maximises the variance of the components, PLSDA maximises the covariance (akin to correlation) between the data and the outcome, hence the amount of explained variance can be lower than PCA (especially in this case, as we have seen already that the major source of variation in the data is not attributable to tumour subtypes). 

1.2 Sample plot: By default, the samples are coloured according to their class membership. Component 1 discriminates `r colorize("green", "RMS")` + `r colorize("blue", "EWS")` vs. `r colorize("grey", "NB")` + `r colorize("orange", "BL")`, component 2 discriminates `r colorize("green", "RMS")` + `r colorize("grey", "NB")` vs. `r colorize("blue", "EWS")` + `r colorize("orange", "BL")`, while component 3 discriminates further the `r colorize("grey", "NB")` and `r colorize("orange", "BL")` groups. It is the combination of all three components that enables us to discriminate all classes.

2.1 Loading plots: each bar represent the contribution (= coefficient) of each gene in each component. Her we only show the top 50 genes with the highest contribution (positive or negative sign, going from the bottom of the graph to the top). `r contrib = 'max'` colors the bars according to the tumour subtype for which the mean expression value is maximal. `r contrib = 'min'` colors the bars according to the tumour subtype for which the mean expression value is minimal. When we change to  `r comp = 2`, we observe a new set of genes and they are colored differently. 

2.2 Loading plots and sample plot. From the sample plot we have observed that component 1 discriminates `r colorize("green", "RMS")` + `r colorize("blue", "EWS")` vs. `r colorize("grey", "NB")` + `r colorize("orange", "BL")`. We observe the same trend at the gene level from the loading plot, showing that these genes are the one driving the separation between this group of samples. (similar interpretation for component 2).

3 Variable plot: here we project the variables in the space spanned by the first two components by calculating the correlation between the variables, and the components (refer to slides). We only show the top genes with a correlation cutoff above 0.7 across both components. We observe a groups of genes that are positively correlated together (left and right hand side on the x-axis), and contribute to component 1 either negatively (left) or positively (right). These two groups are negatively correlated to each other. The trend is not as clear for component 2 (less genes and contribute less to component 2 on the y-axis).


4 Biplot: overlays both samples (as dots) and variables (as arrows). Here we only show the top genes with a correlation cutoff above 0.7 across both components. We can now visualise the same set of genes as in the correlation circle plot, and how they relate (are over / under expressed) with the samples. 

5 Genes that 'points' towards a specific group of samples tend to be overexpressed in these samples.

:::

<!-- end solutions -->


## Sparse PLS-DA for variable selection

We run similar command lines, but this time we use *sparse PLS-DA* that will enable us to select the top discriminant variables. 

<p>
::: info
**â Sparse means zeroes in the loading vectors **

*Sparse* stands for loading vectors that are sparse (include zeroes) because of we use lasso regularisation in the method [@Lec11] so that only a subset of variables are used to calculate the components in the linear combination. 
:::
</p>





The variable selection process is done within PLS-DA. For this, we need to specify the number of variables to select per component.

```{r 02-splsda, results = 'hide', fig.show='hide'}
splsda.srbct <- splsda(X,Y, ncomp = 3,
                       keepX = c(20, 10, 10) # select 20 genes on the first component, 10 on the second, and 30 on the third component
                       )

plotIndiv(splsda.srbct, ind.names = FALSE, legend=TRUE,
          comp=c(1,2), 
          title = 'PLS-DA on SRBCT comp 1-2')

plotLoadings(splsda.srbct, 
             contrib = 'max',  # max = which class has maximum mean (median) expression (vs. min)
             method = 'mean',  # choose either mean or median
             comp = 1)

plotVar(splsda.srbct)  # variable plot (correlation circle plot)

selectVar(splsda.srbct) #extracts the list of variables selected, and their loading weights
```

## Exercise 3: Interpretation

Run the code above, line by line.

1. What are the differences that you observe, compared to the full PLS-DA run previously (i.e with no variable selection). 

2. Plot a sample plot for components 1. vs 3, what do you observe? Also plot the loadings for component 3.

2. Change the values of the `keepX` argument, do you notice large changes?

3. Conclude on the advantages / disadvantages of using sparse PLS-DA for variable selection.

**Sorry!** we currently have a bug with the biplot that we need to fix!

<button onclick="myFunction(&#39;q3&#39;)">

Show solutions

</button>

::: {#q3 style="display:none"}

#### Answers

1. On the sample plot, the `r colorize("grey", "NB")` and `r colorize("green", "RMS")` are clustered together, whereas the other groups are well separated from each other. Component 1 discriminates  `r colorize("orange", "BL")` vs. the other classes. Component 2 discriminates mostly `r colorize("orange", "BL")` vs `r colorize("blue", "EWS")` vs the others. The loading plot is now much clearer (only one color shown on each side of the positive / negative sign). The loading plot only shows the variables that were selected on each component. Similarly for the correlation circle plot, genes are now better aligned on either the x- or y- axis with stronger contribution.

2. Sample plot of comp 1 vs comp 2 now shows a clearer separation on comp 3 of `r colorize("grey", "NB")` vs. `r colorize("green", "RMS")`. This is also reflected in the loading plot on component 3.

3. If we stick to values that are not too large (i.e up to 50 or so), then the plots and trends remain the same. When the keepX values get very large, then we tend to obtain the same results as PLS-DA.


4. Conclusion: sPLS-DA can help identifying key discriminative genes for each sample group. It does so by adopting a 'one group' vs 'all' (or 1 group vs another group) per component. This enables us to identify which genes discriminate which class. The output results are usually neater than a classic PLS-DA. The main challenge is to decide how many genes we should select per component. We do this using repeated cross-validation and estimating the classification error. This is outside the scope of this workshop, but you can have a look at our examples in http://mixomics.org/case-studies/splsda-srbct-case-study/. There are also functions in mixOmics to estimate the classification performance of the final sPLS-DA.

:::

<!-- end solutions -->


# 3. DIABLO to integrate multi-omics datasets
DIABLO is a a method to integrate multiple data sets while explaining their relationship with a categorical outcome variable. DIABLO stands for **D**ata **I**ntegration **A**nalysis for **B**iomarker discovery using **L**atent variable approaches for **O**mics studies [@Sin19]. It can also be referred to as Multiblock (s)PLS-DA. 

<p>
::: info
**â We need the same samples across all omics**

One pre-requisite of DIABLO is that the same samples / individuals should be measured across all omics. This is because we are looking for correlation / covariance between the data sets by calculating the covariance between components (all of length $N$, the number of samples).
:::
</p>



## TCGA case study {#03:diablo}

Human breast cancer is a heterogeneous disease in terms of molecular alterations, cellular composition, and clinical outcome. Breast tumours can be classified into several subtypes, according to their levels of mRNA expression [@Sor01]. Here we consider a subset of data generated by The Cancer Genome Atlas Network [@TCGA12]. For the package, data were normalised, and then drastically prefiltered for illustrative purposes. 

The data were divided into a *training set* with a subset of 150 samples from the mRNA, miRNA and proteomics data, and a *test set* including 70 samples, but only with mRNA and miRNA data (the proteomics data are missing). The aim of this integrative analysis is to identify a highly correlated multi-omics signature discriminating the breast cancer subtypes Basal, Her2 and LumA. 

The `breast.TCGA` (more details can be found in `?breast.TCGA`) is a list containing training and test sets of omics data `data.train` and `data.test` which include:

- `$miRNA`: A data frame with 150 (70) rows and 184 columns in the training (test) data set for the miRNA expression levels,
- `$mRNA`: A data frame with 150 (70) rows and 520 columns in the training (test) data set for the mRNA expression levels,
- `$protein`: A data frame with 150 rows and 142 columns in the training data set for the protein abundance (there are no proteomics in the test set),
- `$subtype`: A factor indicating the breast cancer subtypes in the training (for 150 samples) and test sets (for 70 samples).

This case study covers an interesting scenario where one omic data set is missing in the test set, but because the method generates a set of components per training data set, we can still assess the prediction or performance evaluation using majority or weighted prediction vote.

## Load the data {#03:diablo-load-data}

We will integrate the expression levels of miRNA, mRNA and the abundance of proteins while discriminating the subtypes of breast cancer, then predict the subtypes of the samples in the test set.

Each omics data matrix is stored into a list of matrices $\boldsymbol X$. Each data frame in $\boldsymbol X$ *should be named* as we will match these names with the `keepX` parameter for variable selection. A factor indicating the class membership of each sample is stored in $\boldsymbol Y$. 

```{r 03-load-data, message=FALSE, warning=FALSE}
data(breast.TCGA)

# Extract training data and name each data frame
# Store as list
X <- list(mRNA = breast.TCGA$data.train$mrna, 
          miRNA = breast.TCGA$data.train$mirna, 
          protein = breast.TCGA$data.train$protein)

# Outcome
Y <- breast.TCGA$data.train$subtype
summary(Y)
```

## Set the design matrix
In DIABLO, we need to specify a design matrix that indicates what is the level of correlation we wish to extract between datasets. In the example below, we ask for a small amount of correlation between these data sets.

```{r 03-design}
design <- matrix(0.1, ncol = length(X), nrow = length(X), 
                dimnames = list(names(X), names(X)))
diag(design) <- 0
design 
```

## DIABLO

Here we decide to run a model with 2 components. The number of variables to keep is listed below in `keepX` (we have decided on this based on tuning calculation based on repeated cross-validation. More details available on our website).


```{r 03-final, message = TRUE, results='hide', fig.show='hide'}
# number of variables to select per dataset and per component (here 2 comps)
list.keepX <- list( mRNA = c(8, 25), miRNA = c(14,5), protein = c(10, 5))

diablo.tcga <- block.splsda(X, Y, ncomp = 2, 
                            keepX = list.keepX, design = design)
# the message tells us that each data set will be linked to the outcome Y for maximal discrimination

# sample plots:
plot(diablo.tcga) # pairs of components across datasets and their correlation

plotIndiv(diablo.tcga, ind.names = FALSE, legend = TRUE)

# variable plots:
plotVar(diablo.tcga, legend = TRUE)

circosPlot(diablo.tcga, , cutoff = 0.7)

plotLoadings(diablo.tcga, contrib = 'max',  # max = which class has maximum mean (median) expression (vs. min)
             method = 'mean',  # choose either mean or median
             comp = 1)

# variable selection
selectVar(diablo.tcga)
```



## Exercise 4: Interpretation

Run the code above, line by line.

1. Sample plots: What do the sample plots `plot` and `plotIndiv` tell you about the ability of DIABLO to extract correlated information between data sets *and* to discriminate sample groups? Are there datasets that are more noisy than others? (remember that we decompose each data matrix with a set of components, and loading vectors).

2. Variable plots: What do the variable plots `plotVar` and  `circosPlot` tell you about the correlation between the variables that were selected by DIABLO? 

3. Loading plots: inspect the loading plots for components 1 and 2. What are the discriminative properties of the variables selected on component 1? and component 2? (the function `selectVar` outputs the list of variables selected, and their loading weights)


<button onclick="myFunction(&#39;q4&#39;)">

Show solutions

</button>

::: {#q4 style="display:none"}

#### Answers

1.1 The `plot` output tells use that the mRNA and protein data sets are the most correlated. The least correlated pair is miRNA and protein. On component 1, DIABLO is able to extract correlated information between the data sets, and we observe some separation between the sample groups. 

1.2 The `plotIndiv` output plots the set of components per data set. The mRNA and the protein datasets have some good discriminative properties. The miRNA dataset is a bit more noisy.

2.1 The variable plot `plotVar` shows a high positive correlation between miRNAs and a few proteins and one mRNA (x-axis, right hand side) or between mRNA and proteins (x-axis, left hand side). These groups are negatively correlated together, as they are either overexpressed in `r colorize("blue", "Basal")` or `r colorize("grey", "LumA")` (confirmed in the loading plots).

2.2 The variable plot `circosPlot` shows mostly a negative correlation between some of the variables, with a cutoff of 0.7.

3 According to the loading plot, the variables selected by DIABLO on component 1 discriminate `r colorize("blue", "Basal")`(positive loading value) vs. `r colorize("grey", "LumA")` (negative loading value), whereas the variables selected by DIABLO on component 2 discriminate `r colorize("orange", "Her2")`(positive loading value) vs. the two other groups (negative loading value).


:::

<!-- end solutions -->


## Prediction on the test set (optional)

The `predict` function associated predicts the class of samples from an external test set. In our specific case, one data set (proteomics) is missing in the test set but the method can still be applied. We need to ensure the names of the blocks correspond exactly to those from the training set:

```{r 03-predict, message = FALSE, results='hide', fig.show='hide'}
# Prepare test set data: here one block (proteins) is missing
data.test.tcga <- list(mRNA = breast.TCGA$data.test$mrna, 
                      miRNA = breast.TCGA$data.test$mirna)

predict.diablo.tcga <- predict(diablo.tcga, newdata = data.test.tcga)
# The warning message will inform us that one block is missing

predict.diablo.tcga # Lists the different outputs
```

The following output is a confusion matrix that compares the real subtypes with the predicted subtypes from our trained DIABLO model on the second component for the prediction distance `centroids.dist` and the prediction scheme `WeightedVote` (each dataset casts a vote):

```{r}
confusion.mat.tcga <- get.confusion_matrix(truth = breast.TCGA$data.test$subtype, 
                     predicted = predict.diablo.tcga$WeightedVote$centroids.dist[,2]) # 2nd component
confusion.mat.tcga
```

From this table, we see that one Basal and one Her2 sample are wrongly predicted as Her2 and Lum A respectively, and 3 LumA samples are wrongly predicted as Her2. The balanced prediction error rate can be obtained as:
```{r}
get.BER(confusion.mat.tcga)
```

It would be worthwhile at this stage to revisit the chosen design of DIABLO to assess the influence of the design on the prediction performance on this test set - even though this back and forth analysis is a  biased criterion to choose the design!

## To go further
We have not discussed how to choose the number of components, or the number of variables `keepX` to select on each dataset. This requires repeated cross-validation. More details on the tuning, and the classification performance of the method can be found here: http://mixomics.org/mixdiablo/diablo-tcga-case-study/

Further details, analyses and vignette are avaiable on www.mixOmics.org


# Session Info

```{r }
sessionInfo()
```

